//! High level manager of the network.
//!
//! A [`Swarm`] contains the state of the network as a whole. The entire
//! behaviour of a libp2p network can be controlled through the `Swarm`.
//! The `Swarm` struct contains all active and pending connections to
//! remotes and manages the state of all the substreams that have been
//! opened, and all the upgrades that were built upon these substreams.
//!
//! # Initializing a Swarm
//!
//! Creating a `Swarm` requires three things:
//!
//!  1. A network identity of the local node in form of a [`PeerId`].
//!  2. An implementation of the [`Transport`] trait. This is the type that
//!     will be used in order to reach nodes on the network based on their
//!     address. See the `transport` module for more information.
//!  3. An implementation of the [`NetworkBehaviour`] trait. This is a state
//!     machine that defines how the swarm should behave once it is connected
//!     to a node.
//!
//! # Network Behaviour
//!
//! The [`NetworkBehaviour`] trait is implemented on types that indicate to
//! the swarm how it should behave. This includes which protocols are supported
//! and which nodes to try to connect to. It is the `NetworkBehaviour` that
//! controls what happens on the network. Multiple types that implement
//! `NetworkBehaviour` can be composed into a single behaviour.
//!
//! # Protocols Handler
//!
//! The [`ProtocolsHandler`] trait defines how each active connection to a
//! remote should behave: how to handle incoming substreams, which protocols
//! are supported, when to open a new outbound substream, etc.
//!

//mod behaviour;
mod connection;
mod control;
mod muxer;
mod network;
mod registry;
mod substream;

pub mod ping;
pub mod identify;

pub mod protocol_handler;

pub use control::Control;
pub use muxer::Muxer;
pub use ping::PingHandler;
pub use protocol_handler::DummyProtocolHandler;

use async_std::task;
use fnv::FnvHashMap;
use futures::channel::{mpsc, oneshot};
use futures::future::Either;
use futures::prelude::*;
use smallvec::SmallVec;
use std::collections::HashSet;
use std::{error, fmt, hash::Hash};

use libp2p_core::multistream::Negotiator;
use libp2p_core::peerstore::PeerStore;
use libp2p_core::secure_io::SecureInfo;
use libp2p_core::transport::TransportListener;
use libp2p_core::upgrade::ProtocolName;
use libp2p_core::{muxing::StreamMuxer, transport::TransportError, Multiaddr, PeerId, Transport};
use libp2p_traits::{Read2, Write2};

use crate::connection::{Connection, ConnectionId, ConnectionLimit, Direction};
use crate::control::SwarmControlCmd;
use crate::network::NetworkInfo;
use crate::ping::{PingConfig};
use crate::registry::Addresses;
use crate::substream::{StreamId, Substream};
use std::time::Duration;
use crate::identify::{IdentifyHandler, IdentifyConfig, RemoteInfo};
use libp2p_core::identity::Keypair;

type Result<T> = std::result::Result<T, SwarmError>;

/// The ID of a single listener.
///
/// It is part of most [`ListenersEvent`]s and can be used to remove
/// individual listeners from the [`ListenersStream`].
#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct ListenerId(u64);

/// A single active listener.
#[derive(Debug)]
struct Listener<TTrans>
where
    TTrans: Transport,
{
    /// The ID of this listener.
    id: ListenerId,
    /// The object that actually listens.
    listener: TTrans::Listener,
}

#[allow(dead_code)]
impl<TTrans> Listener<TTrans>
where
    TTrans: Transport,
{
    pub fn new(listener: TTrans::Listener, id: ListenerId) -> Self {
        Listener { id, listener }
    }
}

/// Event generated by the `Swarm`.
#[derive(Debug)]
pub enum SwarmEvent<TStreamMuxer> {
    /// A connection to the given peer has been opened.
    ConnectionEstablished {
        /// The connection, stream muxer
        stream_muxer: TStreamMuxer,
        /// Direction of the connection
        direction: Direction,
        /*
                /// Number of connections_by_peer connections to this peer, including the one that has just been
                /// opened.
                num_established: NonZeroU32,
        */
    },
    /// A connection with the given peer has been closed.
    ConnectionClosed {
        /// The connection Id of the sub stream.
        cid: ConnectionId,
        /// The cause of the error.
        error: TransportError,
    },
    /// A stream failed to negotiate protocol with peer.
    StreamError {
        /// The connection Id of the sub stream.
        cid: ConnectionId,
        /// The cause of the error.
        error: TransportError,
    },
    /// A new substream opened.
    StreamOpened {
        /// The direction of the substream.
        dir: Direction,
        /// The connection Id of the sub stream.
        cid: ConnectionId,
        /// The substream Id.
        sid: StreamId,
    },
    /// A substream has been closed.
    StreamClosed {
        /// The direction of the substream.
        dir: Direction,
        /// The connection Id of the sub stream.
        cid: ConnectionId,
        /// The substream Id.
        sid: StreamId,
    },
    /// An error happened on a connection during its initial handshake.
    ///
    /// This can include, for example, an error during the handshake of the encryption layer, or
    /// the connection unexpectedly closed.
    IncomingConnectionError {
        /// Local connection address.
        /// This address has been earlier reported with a [`NewListenAddr`](SwarmEvent::NewListenAddr)
        /// event.
        local_addr: Multiaddr,
        /// Address used to send back data to the remote.
        send_back_addr: Multiaddr,
        // The error that happened.
        error: TransportError,
    },
    OutgoingConnectionError {
        /// The remote Peer Id
        peer_id: PeerId,
        /// The remote multiaddr
        remote_addr: Multiaddr,
        /// The error that happened when dialing
        error: SwarmError,
    },
    /// We connected to a peer, but we immediately closed the connection because that peer is banned.
    BannedPeer {
        /// Identity of the banned peer.
        peer_id: PeerId,
    },
    /// Tried to dial an address but it ended up being unreachaable.
    UnreachableAddr {
        /// `PeerId` that we were trying to reach.
        peer_id: PeerId,
        /// Address that we failed to reach.
        address: Multiaddr,
        // /// Error that has been encountered.
        // error: PendingConnectionError<io::Error>,
        /// Number of remaining connection attempts that are being tried for this peer.
        attempts_remaining: u32,
    },
    /// Tried to dial an address but it ended up being unreachaable.
    /// Contrary to `UnreachableAddr`, we don't know the identity of the peer that we were trying
    /// to reach.
    UnknownPeerUnreachableAddr {
        /// Address that we failed to reach.
        address: Multiaddr,
        // /// Error that has been encountered.
        // error: PendingConnectionError<io::Error>,
    },
    /// One of our listeners has reported a new local listening address.
    NewListenAddr(Multiaddr),
    /// One of our listeners has reported the expiration of a listening address.
    ExpiredListenAddr(Multiaddr),
    /// One of the listeners gracefully closed.
    ListenerClosed {
        /// The addresses that the listener was listening on. These addresses are now considered
        /// expired, similar to if a [`ExpiredListenAddr`](SwarmEvent::ExpiredListenAddr) event
        /// has been generated for each of them.
        addresses: Vec<Multiaddr>,
        /// Reason for the closure. Contains `Ok(())` if the stream produced `None`, or `Err`
        /// if the stream produced an error.
        reason: TransportError,
    },
    /// A new dialing attempt has been initiated.
    ///
    /// A [`ConnectionEstablished`](SwarmEvent::ConnectionEstablished)
    /// event is reported if the dialing attempt succeeds, otherwise a
    /// [`UnreachableAddr`](SwarmEvent::UnreachableAddr) event is reported
    /// with `attempts_remaining` equal to 0.
    Dialing(PeerId),

    /// A Ping result generated by a connection.
    PingResult {
        /// The connection Id.
        cid: ConnectionId,
        /// The result.
        /// Duration means the TTL when succeeded, or SwarmError for failed.
        result: Result<Duration>,
    },
    IdentifyResult {
        /// The connection Id.
        cid: ConnectionId,
        /// The result.
        /// Duration means the TTL when succeeded, or SwarmError for failed.
        result: Result<RemoteInfo>,
    },
}

type ProtocolId = &'static [u8];

/// Contains the state of the network, plus the way it should behave.
pub struct Swarm<TTrans>
where
    TTrans: Transport + Clone,
    TTrans::Output: StreamMuxer,
{
    pub peers: PeerStore,

    muxer: Muxer<<TTrans::Output as StreamMuxer>::Substream>,

    //protocol_handlers: FnvHashMap<ProtocolId, BoxHandler<<TTrans::Output as StreamMuxer>::Substream>>,
    /// The Transport
    transport: TTrans,

    /// The local peer ID.
    local_peer_id: PeerId,

    /// The next listener ID to assign.
    next_connection_id: usize,

    /*
        /// Handles which nodes to connect to and how to handle the events sent back by the protocol
        /// handlers.
        behaviour: TBehaviour,

    */
    /// List of multiaddresses we're listening on.
    listened_addrs: SmallVec<[Multiaddr; 8]>,

    /// List of multiaddresses we're listening on, after account for external IP addresses and
    /// similar mechanisms.
    external_addrs: Addresses,

    /// List of nodes for which we deny any incoming connection.
    banned_peers: HashSet<PeerId>,

    /// The all connections_by_peer connections organized by their Ids
    connections_by_id: FnvHashMap<ConnectionId, Connection<TTrans::Output>>,
    /// The all connections_by_peer connections by  peer Id
    /// There might be more than one connections for a remote peer
    connections_by_peer: FnvHashMap<PeerId, Vec<ConnectionId>>,

    /// Swarm Ping service config, optional.
    /// Ping service will be started as long as a new connection is established, if enabled.
    /// The connection will be closed if Ping failure reaches the maxmium failure counts.
    ping: Option<PingConfig>,
    /// Swarm Identify service config, optional.
    /// Identify service will be started as long as a new connection is established, if enabled.
    identify: Option<IdentifyConfig>,

    //
    // /// Pending event to be delivered to connection handlers
    // /// (or dropped if the peer disconnected) before the `behaviour`
    // /// can be polled again.
    // pending_event: Option<(PeerId, PendingNotifyHandler, TInEvent)>
    /// Swarm will listen on this channel, waiting for events generated from underlying transport
    event_receiver: mpsc::UnboundedReceiver<SwarmEvent<TTrans::Output>>,
    /// The Swarm event sender wil be cloned and then taken by underlying parts
    event_sender: mpsc::UnboundedSender<SwarmEvent<TTrans::Output>>,

    /// Swarm will listen on this channel, for external control commands
    ctrl_receiver: mpsc::Receiver<SwarmControlCmd<Substream<<TTrans::Output as StreamMuxer>::Substream>>>,
    /// The Swarm event sender wil be cloned and then taken by others
    ctrl_sender: mpsc::Sender<SwarmControlCmd<Substream<<TTrans::Output as StreamMuxer>::Substream>>>,
}

// impl<TBehaviour, TInEvent, TOutEvent, THandler, TConnInfo> Unpin for
//     Swarm<TBehaviour, TInEvent, TOutEvent, THandler, TConnInfo>
// where
//     THandler: IntoProtocolsHandler,
//     TConnInfo: ConnectionInfo<PeerId = PeerId>,
// {
// }
#[allow(dead_code)]
impl<TTrans> Swarm<TTrans>
where
    TTrans: Transport + Clone + 'static,
    TTrans::Listener: 'static,
    TTrans::Output: StreamMuxer + SecureInfo,
    <TTrans::Output as StreamMuxer>::Substream: Read2 + Write2 + Send + Unpin,
{
    /// Builds a new `Swarm`.
    pub fn new(
        transport: TTrans,
        local_peer_id: PeerId,
        muxer: Muxer<<TTrans::Output as StreamMuxer>::Substream>, //_config: NetworkConfig,
    ) -> Self
    {
        // unbounded channel for events, so that we can send a message to ourselves
        let (event_tx, event_rx) = mpsc::unbounded();
        let (ctrl_tx, ctrl_rx) = mpsc::channel(0);
        Swarm {
            peers: PeerStore::default(),
            muxer,
            transport,
            local_peer_id,
            // listeners: SmallVec::with_capacity(16),
            next_connection_id: 0,
            listened_addrs: Default::default(),
            external_addrs: Default::default(),
            banned_peers: Default::default(),
            connections_by_id: Default::default(),
            connections_by_peer: Default::default(),
            ping: None,
            identify: None,
            event_receiver: event_rx,
            event_sender: event_tx,
            ctrl_receiver: ctrl_rx,
            ctrl_sender: ctrl_tx,
        }
    }

    fn assign_cid(&mut self) -> usize {
        self.next_connection_id += 1;
        self.next_connection_id
    }

    /// Creates Swarm with Ping service.
    pub fn with_ping(mut self, ping: PingConfig) -> Self {
        self.ping = Some(ping);
        self.muxer.add_protocol_handler(Box::new(PingHandler));
        self
    }
    /// Creates Swarm with Identify service.
    pub fn with_identify(mut self, id: IdentifyConfig) -> Self {
        self.identify = Some(id);
        let protocols = self.muxer.supported_protocols().into_iter().map(|p| p.protocol_name_str().to_string()).collect();
        // TODO: public key
        let handler = IdentifyHandler::new(Keypair::generate_secp256k1().public(), protocols);
        self.muxer.add_protocol_handler(Box::new(handler));
        self
    }

    /// Get a controller for Swarm.
    pub fn control(&self) -> Control<Substream<<TTrans::Output as StreamMuxer>::Substream>> {
        Control::new(self.ctrl_sender.clone())
    }

    /// Makes progress for Swarm
    /// in general, it should be spawned in a Task
    pub async fn next(&mut self) -> Result<()> {
        // TODO: check if terminated??

        // handle messages, which makes actual progress for Swarm
        self.handle_messages().await?;

        Ok(())
    }

    /// Handles events generated internally or externally
    ///
    /// invoked from `next_stream`
    async fn handle_messages(&mut self) -> Result<()> {
        loop {
            let either = future::select(self.event_receiver.next(), self.ctrl_receiver.next()).await;
            match either {
                Either::Left((evt, _)) => {
                    if let Some(evt) = evt {
                        self.on_event(evt)?;
                    } else {
                        // we are closed anyway, break
                        log::debug!("Swarm event channel is closed, closing down...");
                        return Err(SwarmError::Closing(1));
                    }
                }
                Either::Right((cmd, _)) => {
                    if let Some(cmd) = cmd {
                        self.on_command(cmd).await?;
                    } else {
                        // we are closed anyway, break
                        log::debug!("Swarm control channel is closed, closing down...");
                        return Err(SwarmError::Closing(2));
                    }
                }
            }
        }
    }

    fn on_event(&mut self, event: SwarmEvent<TTrans::Output>) -> Result<()> {
        log::trace!("Swarm event={:?}", event);

        match event {
            SwarmEvent::ListenerClosed { addresses: _, reason: _ } => {}
            SwarmEvent::ConnectionEstablished { stream_muxer, direction } => {
                let _ = self.handle_connection_opened(stream_muxer, direction);
            },
            SwarmEvent::ConnectionClosed { cid, error: _ } => {
                let _ = self.handle_connection_closed(cid);
            },
            SwarmEvent::OutgoingConnectionError {
                peer_id: _,
                remote_addr: _,
                error: _,
            } => {
                // TODO: add statistics
            },
            SwarmEvent::StreamError { .. } => {
                // TODO: add statistics
            },
            SwarmEvent::StreamOpened { dir, cid, sid } => {
                let _ = self.handle_stream_opened(dir, cid, sid);
            },
            SwarmEvent::StreamClosed { dir, cid, sid } => {
                let _ = self.handle_stream_closed(dir, cid, sid);
            },
            SwarmEvent::PingResult { cid, result } => {
                let _ = self.handle_ping_result(cid, result);
            },
            SwarmEvent::IdentifyResult { cid, result } => {
                let _ = self.handle_identify_result(cid, result);
            },

            // TODO: handle other messages
            e => {
                log::warn!("TODO: unhandled swarm events {:?}", e);
            }
        }

        Ok(())
    }

    async fn on_command(&mut self, cmd: SwarmControlCmd<Substream<<TTrans::Output as StreamMuxer>::Substream>>) -> Result<()> {
        log::trace!("Swarm control command={:?}", cmd);

        match cmd {
            SwarmControlCmd::NewConnection(peer_id, reply) => {
                // got the peer_id, start the dialer for it
                let _ = self.on_new_connection(peer_id, reply);
            }
            SwarmControlCmd::CloseConnection(peer_id, reply) => {
                // got the peer_id, close all connections to the peer
                let _ = self.on_close_connection(peer_id, reply);
            }
            SwarmControlCmd::NewStream(peer_id, pids, reply) => {
                // got the peer_id, try opening a new sub stream
                let _ = self.on_new_stream(peer_id, pids, reply);
            }
            SwarmControlCmd::CloseStream(stream, reply) => {
                // got the peer_id, try opening a new sub stream
                let _ = self.on_close_stream(stream, reply).await;
            }
            SwarmControlCmd::NetworkInfo(reply) => {
                // got the peer_id, try opening a new sub stream
                let _ = self.on_retrieve_networkinfo(reply);
            }
            SwarmControlCmd::CloseSwarm => {
                log::info!("closing the swarm...");
                let _ = self.event_sender.close_channel();
            }
            // TODO:
            //_ => {}
        }

        Ok(())
    }

    fn on_new_connection(&mut self, peer_id: PeerId, reply: oneshot::Sender<Result<()>>) -> Result<()> {
        // return if we already have the connection, otherwise, start dialing
        if let Some(_conn) = self.get_best_conn(&peer_id) {
            let _ = reply.send(Ok(()));
        } else {
            // Note: reply moved
            let _ = self.start_dialer(peer_id, Some(reply));
        }
        Ok(())
    }

    fn on_close_connection(&mut self, peer_id: PeerId, reply: oneshot::Sender<Result<()>>) -> Result<()> {
        if let Some(ids) = self.connections_by_peer.get(&peer_id) {
            // close all connections realted to the peer_id
            for id in ids {
                self.connections_by_id.get(&id).map(|c| c.close());
            }
        }

        let _ = reply.send(Ok(()));
        Ok(())
    }

    fn on_new_stream(
        &mut self,
        peer_id: PeerId,
        pids: Vec<ProtocolId>,
        reply: oneshot::Sender<Result<Substream<<TTrans::Output as StreamMuxer>::Substream>>>,
    ) -> Result<()> {
        if let Some(connection) = self.get_best_conn(&peer_id) {
            // well, we have a connection, start a task to open the stream
            let cid = connection.id();
            let stream_muxer = connection.stream_muxer().clone();
            let tx = self.event_sender.clone();
            task::spawn(async move {
                let r = open_stream(cid, stream_muxer, pids, tx).await;
                let _ = reply.send(r);
            });
        } else {
            let _ = reply.send(Err(SwarmError::NoConnection(peer_id)));
        }
        Ok(())
    }

    async fn on_close_stream(
        &mut self,
        substream: Substream<<TTrans::Output as StreamMuxer>::Substream>,
        reply: oneshot::Sender<Result<()>>,
    ) -> Result<()> {
        let cid = substream.cid();
        let sid = substream.id();
        let _ = self
            .event_sender
            .send(SwarmEvent::StreamClosed {
                dir: Direction::Outbound,
                cid,
                sid,
            })
            .await;
        //self.handle_stream_closed(Direction::Outbound, cid, sid);
        let _ = reply.send(Ok(()));
        Ok(())
    }
    ///
    fn on_retrieve_networkinfo(&mut self, reply: oneshot::Sender<Result<NetworkInfo>>) -> Result<()> {
        let _ = reply.send(Ok(self.network_info()));
        Ok(())
    }

    /// Starts Swarm background task
    /// handling the internal events and external controls
    pub fn start(self) {
        // well, self 'move' explicitly,
        let mut swarm = self;

        task::spawn(async move { while let Ok(()) = swarm.next().await {} });
    }

    /// Returns the transport passed when building this object.
    pub fn transport(&self) -> &TTrans {
        &self.transport
    }

    /// Returns information about the [`Network`] underlying the `Swarm`.
    pub fn network_info(&self) -> NetworkInfo {
        // TODO: add stats later on
        let num_connections_established = self.connections_by_id.len();
        let num_connections_pending = 0; //self.pool.num_pending();
        let num_connections = num_connections_established + num_connections_pending;
        let num_peers = self.connections_by_peer.len();
        let num_active_streams = self.connections_by_id.iter().fold(0, |acc, (_k, v)| acc + v.num_streams());
        NetworkInfo {
            num_peers,
            num_connections,
            num_connections_established,
            num_connections_pending,
            num_active_streams,
        }
    }

    /// Starts listening on the given address.
    ///
    /// Returns an error if the address is not supported.
    /// TODO: addr: Multiaddr might be a Vec<Multiaddr>
    pub fn listen_on(&mut self, addr: Multiaddr) -> Result<()> {
        let mut listener = self.transport.clone().listen_on(addr)?;

        self.listened_addrs.push(listener.multi_addr());

        // let id = self.next_id;
        // self.next_id = ListenerId(self.next_id.0 + 1);

        let mut tx = self.event_sender.clone();
        // start a task for this listener
        task::spawn(async move {
            loop {
                let r = listener.accept().await;
                match r {
                    Ok(muxer) => {
                        // dont have to verify if remote peer id matches its public key
                        // always accept any incoming connection

                        // send muxer back to Swarm main task
                        let _ = tx
                            .send(SwarmEvent::ConnectionEstablished {
                                stream_muxer: muxer,
                                direction: Direction::Inbound,
                            })
                            .await;
                    }
                    Err(err) => {
                        let _ = tx
                            .send(SwarmEvent::ListenerClosed {
                                addresses: vec![],
                                reason: err,
                            })
                            .await;
                    }
                }
            }
        });
        Ok(())
    }

    /*    /// Remove some listener.
        ///
        /// Returns `Ok(())` if there was a listener with this ID.
        pub fn remove_listener(&mut self, id: ListenerId) -> Result<()> {
            if let Some(i) = self.listeners.iter().position(|l| l.id == id) {
                self.listeners.remove(i);
                Ok(())
            } else {
                Err(SwarmError::Internal)
            }
        }
    */
    /// Tries to dial the given address.
    ///
    /// Returns an error if the address is not supported.
    fn dial_peer_with_addr(&mut self, peer_id: PeerId, addr: Multiaddr, reply: Option<oneshot::Sender<Result<()>>>) {
        // TODO: add dial limiter...

        log::trace!("dialing addr={:?}, expecting {:?}", addr, peer_id);

        let mut tx = self.event_sender.clone();
        let transport = self.transport().clone();
        task::spawn(async move {
            let r = transport.dial(addr.clone()).await;
            let response = match r {
                Ok(mut stream_muxer) => {
                    // test if the PeerId matches expectation, otherwise,
                    // it is a bad outgoing connection
                    if peer_id == stream_muxer.remote_peer() {
                        let _ = tx
                            .send(SwarmEvent::ConnectionEstablished {
                                stream_muxer,
                                direction: Direction::Outbound,
                            })
                            .await;
                        Ok(())
                    } else {
                        let wrong_id = stream_muxer.remote_peer();
                        log::info!(
                            "bad connection, peerid mismatch conn={:?} wanted={:?} got={:?}",
                            stream_muxer,
                            peer_id,
                            wrong_id
                        );
                        let _ = tx
                            .send(SwarmEvent::OutgoingConnectionError {
                                peer_id,
                                remote_addr: addr,
                                error: SwarmError::Internal,
                            })
                            .await;
                        // close this connection
                        let _ = stream_muxer.close().await;

                        Err(SwarmError::InvalidPeerId(wrong_id))
                    }
                }
                Err(err) => {
                    let _ = tx
                        .send(SwarmEvent::OutgoingConnectionError {
                            peer_id,
                            remote_addr: addr,
                            error: SwarmError::Internal,
                        })
                        .await;

                    Err(SwarmError::Transport(err))
                }
            };
            reply.map(|reply| reply.send(response));
        });
    }

    /// Starts a dialing task
    /// reply is optional, it might be 'None' when dialer is initiated internally
    pub fn start_dialer(&mut self, peer_id: PeerId, reply: Option<oneshot::Sender<Result<()>>>) -> Result<()> {
        log::trace!("dialer, looking for {:?}", peer_id);

        // TODO: find a better way to handle multiple addresses of PeerId
        if let Some(addrs) = self.peers.addrs.get_addr(&peer_id) {
            // TODO: handle multiple addresses

            // TODO: add dial limiter...

            let addr = addrs.first().expect("must have one").clone();
            self.dial_peer_with_addr(peer_id, addr, reply);

            Ok(())
        } else {
            Err(SwarmError::NoAddresses(peer_id))
        }
    }

    /// Tries to initiate a dialing attempt to the given peer.
    ///
    pub async fn dial_peer(&mut self, peer_id: PeerId) -> Result<()> {
        if let Some(_conn) = self.get_best_conn(&peer_id) {
            Ok(())
        } else {
            self.start_dialer(peer_id, None)
        }
    }

    fn get_best_conn(&mut self, peer_id: &PeerId) -> Option<&mut Connection<TTrans::Output>> {
        let mut best = None;
        // selects the best connection we have to the peer.
        // TODO: we might have multiple connections towards a PeerId

        log::trace!("trying to get the best connnection for {:?}", peer_id);

        self.connections_by_peer.iter().for_each(|(k, v)| log::info!("{:?}={:?}", k, v));

        //let v = self.connections_by_peer.get_mut(peer_id).unwrap();

        if let Some(ids) = self.connections_by_peer.get(peer_id) {
            // TODO: to check if this connection is being closed

            let mut len = 0;
            for id in ids.iter() {
                if let Some(connection) = self.connections_by_id.get(id) {
                    let num = connection.num_streams();
                    if num >= len {
                        len = num;
                        best = Some(id);
                    }
                }
            }
        }

        if let Some(id) = best {
            self.connections_by_id.get_mut(id)
        } else {
            None
        }
    }

    fn is_connected(&self, peer_id: &PeerId) -> bool {
        // TODO: check if the connection is being closed??
        self.connections_by_peer.get(peer_id).map_or(0, |v| v.len()) > 0
    }

    /*
        /// Tries to initiate a dialing attempt to the given peer.
        ///
        /// If a new dialing attempt has been initiated, `Ok(true)` is returned.
        ///
        /// If no new dialing attempt has been initiated, meaning there is an ongoing
        /// dialing attempt or `addresses_of_peer` reports no addresses, `Ok(false)`
        /// is returned.
        pub fn dial(&mut self, peer_id: &PeerId) -> Result<(), SwarmError> {
            let self_listening = &self.listened_addrs;
            let mut addrs = self.behaviour.addresses_of_peer(peer_id)
                .into_iter()
                .filter(|a| !self_listening.contains(a));

            let result =
                if let Some(first) = addrs.next() {
                    let handler = self.behaviour.new_handler().into_node_handler_builder();
                    self.network.peer(peer_id.clone())
                        .dial(first, addrs, handler)
                        .map(|_| ())
                        .map_err(SwarmError::ConnectionLimit)
                } else {
                    Err(SwarmError::NoAddresses)
                };

            if let Err(error) = &result {
                log::debug!(
                    "New dialing attempt to peer {:?} failed: {:?}.",
                    peer_id, error);
                self.behaviour.inject_dial_failure(&peer_id);
            }

            result
        }
        /// Returns an iterator that produces the list of addresses we're listening on.
        pub fn listeners(&self) -> impl Iterator<Item = &Multiaddr> {
            self.listeners.iter().flat_map(|l| l.addresses.iter())
        }
    */
    /*
    /// Set a handler for sub streams, with a protocol id
    ///
    /// , f: F)
    //     where F: FnMut(<TTrans::Output as StreamMuxer>::Substream
    fn set_stream_handler<F>(&mut self, pid: TProto)
    {
        self.muxer.add_handler(pid, Box::new(f));
    }*/

    /// Returns an iterator that produces the list of addresses that other nodes can use to reach
    /// us.
    pub fn external_addresses(&self) -> impl Iterator<Item = &Multiaddr> {
        self.external_addrs.iter()
    }

    /// Returns the peer ID of the swarm passed as parameter.
    pub fn local_peer_id(&self) -> &PeerId {
        &self.local_peer_id
    }

    /// Adds an external address.
    ///
    /// An external address is an address we are listening on but that accounts for things such as
    /// NAT traversal.
    pub fn add_external_address(&mut self, addr: Multiaddr) {
        self.external_addrs.add(addr)
    }
    /*
        /// Obtains a view of a [`Peer`] with the given ID in the network.
        pub fn peer(&mut self, peer_id: TPeerId)
                    -> Peer<'_, TTrans, TInEvent, TOutEvent, THandler, TConnInfo, TPeerId>
        {
            Peer::new(self, peer_id)
        }

        /// Returns the connection info for an arbitrary connection with the peer, or `None`
        /// if there is no connection to that peer.
        // TODO: should take &self instead of &mut self, but the API in network requires &mut
        pub fn connection_info(&mut self, peer_id: &PeerId) -> Option<TConnInfo> {
            if let Some(mut n) = self.network.peer(peer_id.clone()).into_connected() {
                Some(n.some_connection().info().clone())
            } else {
                None
            }
        }
    */
    /// Bans a peer by its peer ID.
    ///
    /// Any incoming connection and any dialing attempt will immediately be rejected.
    /// This function has no effect is the peer is already banned.
    pub fn ban_peer_id(&mut self, peer_id: PeerId) {
        self.banned_peers.insert(peer_id);

        // TODO: to disconnect
        // if let Some(c) = self.network.peer(peer_id).into_connected() {
        //     c.disconnect();
        // }
    }

    /// Unbans a peer.
    pub fn unban_peer_id(&mut self, peer_id: PeerId) {
        self.banned_peers.remove(peer_id.as_ref());
    }

    fn add_connection(&mut self, connection: Connection<TTrans::Output>) {
        let cid = connection.id();
        let remote_peer_id = connection.remote_peer();

        // append to the by_id hashmap
        self.connections_by_id.insert(cid, connection);

        // append to the by peer hashmap
        let conns = self.connections_by_peer.entry(remote_peer_id).or_default();
        conns.push(cid);

        log::trace!("connection added to hashmap, total={}", self.connections_by_id.len());

        // TODO: we have a connection to the specified peer_id, now cancel all pending attempts

        // TODO: generate a connected event

        // TODO: return the connection

        // start Ping service if need
    }

    /// Handles a new connection
    ///
    /// start a Task for accepting new sub-stream from the connection
    fn handle_connection_opened(&mut self, stream_muxer: TTrans::Output, dir: Direction) -> Result<()> {
        log::trace!("handle_connection_opened: {:?} {:?}", stream_muxer, dir);

        // clone the stream_muxer, and then wrap into Connection, task_handle will be assigned later
        let mut connection = Connection::new(self.assign_cid(), stream_muxer.clone(), dir);

        // TODO: filtering the multiaddr, Err = AddrFiltered(addr)

        /*        raddr := tc.RemoteMultiaddr()
                if s.Filters.AddrBlocked(raddr) {
                    tc.Close()
                    return nil, ErrAddrFiltered
                }

                p := tc.RemotePeer()

                // Add the public key.
                if pk := tc.RemotePublicKey(); pk != nil {
                    s.peers.AddPubKey(p, pk)
                }
        */
        // TODO: add remote pubkey to keystore

        let mut tx = self.event_sender.clone();
        let cid = connection.id();
        // clone muxer and move it into the task
        let mut muxer = self.muxer.clone();

        // Note we have to use the original copy of the stream muxer to start the task,
        // instead of the cloned one which doesn't have the task handle at all
        let handle = task::spawn(async move {
            let mut stream_muxer = stream_muxer;
            // start the background task of the stream_muxer, the handle can be await'ed by us
            let task_handle = stream_muxer.task().map(task::spawn);
            loop {
                let r = stream_muxer.accept_stream().await;

                // TODO: probably we should spawn a new task for protocol selection
                // But in go-libp2p, the protocol selection is done in a blocking way...

                match r {
                    Ok(raw_stream) => {
                        // well, got the raw stream, now do protocol selection
                        log::trace!("run protocol selection for inbound stream={:?}", raw_stream);

                        // now it's time to do multistream multiplexing for inbound stream
                        let result = muxer.select_inbound(raw_stream).await;
                        match result {
                            Ok((mut handler, raw_stream, proto)) => {
                                let stream = Substream::new(raw_stream, Direction::Inbound, proto, cid);
                                let sid = stream.id();
                                let _ = tx
                                    .send(SwarmEvent::StreamOpened {
                                        dir: Direction::Inbound,
                                        cid,
                                        sid,
                                    })
                                    .await;

                                // anyway, start handler task
                                let mut tx = tx.clone();
                                task::spawn(async move {
                                    let _ = handler.handle(stream, proto).await;
                                    let _ = tx
                                        .send(SwarmEvent::StreamClosed {
                                            dir: Direction::Inbound,
                                            cid,
                                            sid,
                                        })
                                        .await;
                                });

                                // TODO: hook the task handle to the Substream, so that it can wait for exiting the task
                            }
                            Err(error) => {
                                let _ = tx.send(SwarmEvent::StreamError { cid, error }).await;
                            }
                        }
                    }
                    Err(error) => {
                        let _ = tx.send(SwarmEvent::ConnectionClosed { cid, error }).await;
                        // something happened, break the loop then exit the Task
                        break;
                    }
                }
            }

            // As stream_muxer is closed, we wait for its task_handle
            if let Some(h) = task_handle {
                h.await;
            }

            log::trace!("accept-task exiting...");
        });

        // now we have the handle, move it into Connection
        connection.set_handle(handle);

        // start Ping service if there is
        self.ping.as_ref().map(|config| {
            log::trace!("starting Ping service for {:?}", connection);
            connection.start_ping(config.timeout, config.interval, self.event_sender.clone());
        });

        // start Ping service if there is
        self.identify.as_ref().map(|config| {
            log::trace!("starting Identify service for {:?}", connection);
            connection.start_identify(self.event_sender.clone());
        });

        // insert to the hashmap of connections
        // there might be a race condition:
        // the spawned connection task might have exited for some reason, before we insert connection
        // into the hashmap. No problem, the connection will be cleaned up in 'handle_connection_closed'
        // event.
        self.add_connection(connection);

        Ok(())
    }

    fn handle_stream_opened(&mut self, dir: Direction, cid: ConnectionId, sid: StreamId) -> Result<()> {
        log::trace!("handle_stream_opened: {:?} {:?}/{:?}", dir, cid, sid);
        // add stream id to the connection substream list
        self.connections_by_id.get_mut(&cid).map(|c| c.add_stream(sid));

        Ok(())
    }

    fn handle_stream_closed(&mut self, dir: Direction, cid: ConnectionId, sid: StreamId) -> Result<()> {
        log::trace!("handle_stream_closed: {:?} {:?}/{:?}", dir, cid, sid);
        // delete stream id from the connection substream list
        self.connections_by_id.get_mut(&cid).map(|c| c.del_stream(sid));

        Ok(())
    }

    /// Handles closing a connection
    ///
    /// start a Task for accepting new sub-stream from the connection
    fn handle_connection_closed(&mut self, cid: ConnectionId) -> Result<()> {
        log::info!("before close {:?}", self.connections_by_id);
        log::info!("before close {:?}", self.connections_by_peer);

        log::trace!("handle_connection_closed: {:?}", cid);

        // try to retrieve the Connection by looking up 'connections_by_id'
        if let Some(mut connection) = self.connections_by_id.remove(&cid) {
            let remote_peer_id = connection.remote_peer();
            if let Some(ids) = self.connections_by_peer.get_mut(&remote_peer_id) {
                ids.retain(|id| id != &cid);
            } else {
                log::warn!("shouldn't happen, PeerId={:?}", remote_peer_id);
            }

            // now, close all tasks owned by the connection
            task::spawn(async move {
                let _ = connection.wait().await;
                let _ = connection.stop_ping().await;
            });
        } else {
            log::info!("shouldn't happen, wired connection {:?}", cid);
        }

        log::info!("after close {:?}", self.connections_by_id);
        log::info!("after close {:?}", self.connections_by_peer);

        Ok(())
    }

    fn handle_ping_result(&mut self, cid: ConnectionId, result: Result<Duration>) -> Result<()> {
        log::trace!("handle_ping_result: {:?} {:?}", cid, result);

        if let Some(connection)= self.connections_by_id.get_mut(&cid) {
            match result {
                Ok(ttl) =>{
                    //let remote_peer_id = c.remote_peer();
                    log::trace!("ping TTL={:?} for {:?}", ttl, connection);
                    // TODO: update peer store with the TTL

                    connection.reset_failure();
                },
                Err(err) => {
                    log::info!("ping failed {:?} for {:?}", err, connection);
                    let allowed_max_failure = self.ping.as_ref().map_or(0, |config|config.max_failures.into());
                    connection.handle_failure(allowed_max_failure);
                }
            }
        }

        Ok(())
    }
    fn handle_identify_result(&mut self, cid: ConnectionId, result: Result<RemoteInfo>) -> Result<()> {
        log::trace!("handle_identify_result: {:?} {:?}", cid, result);

        if let Some(connection)= self.connections_by_id.get_mut(&cid) {
            match result {
                Ok(info) =>{
                    //let remote_peer_id = c.remote_peer();
                    log::trace!("identify info={:?} for {:?}", info, connection);
                    // TODO: update peer store with the TTL
                },
                Err(err) => {
                    log::info!("identify failed {:?} for {:?}", err, connection);
                }
            }
        }

        Ok(())
    }
}

/// Connections to notify of a pending event.
///
/// The connection IDs to notify of an event are captured at the time
/// the behaviour emits the event, in order not to forward the event
/// to new connections which the behaviour may not have been aware of
/// at the time it issued the request for sending it.
#[allow(dead_code)]
enum PendingNotifyHandler {
    One(ConnectionId),
    Any(SmallVec<[ConnectionId; 10]>),
    All(SmallVec<[ConnectionId; 10]>),
}

/// The possible failures of [`Swarm`].
#[derive(Debug)]
pub enum SwarmError {
    /// The configured limit for simultaneous outgoing connections
    /// has been reached.
    ConnectionLimit(ConnectionLimit),
    /// Returned no addresses for the peer to dial.
    NoAddresses(PeerId),
    /// No connection yet, unable to open a sub stream.
    NoConnection(PeerId),
    /// The peer identity obtained on the connection did not
    /// match the one that was expected.
    InvalidPeerId(PeerId),

    /// Closing down. Swarm is being closed at this moment
    /// 1: event channel, 2: ctrl channel
    Closing(u32),

    /// Transport Error
    ///
    /// Contains a TransportError.
    Transport(TransportError),

    /// Internal, tentatively for convenience
    Internal,
}

impl fmt::Display for SwarmError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            SwarmError::ConnectionLimit(err) => write!(f, "Swarm Dial error: {}", err),
            SwarmError::NoAddresses(peer_id) => write!(f, "Swarm Dial error: no addresses for peer{:?}.", peer_id),
            SwarmError::NoConnection(peer_id) => write!(f, "Swarm Stream error: no connections for peer{:?}.", peer_id),
            SwarmError::InvalidPeerId(peer_id) => write!(f, "Swarm Dial error: invalid peer id{:?}.", peer_id),
            SwarmError::Transport(err) => write!(f, "Swarm Transport error: {}.", err),
            SwarmError::Internal => write!(f, "Swarm internal error."),
            SwarmError::Closing(s) => write!(f, "Swarm channel closed source={}.", s),
        }
    }
}

impl error::Error for SwarmError {
    fn source(&self) -> Option<&(dyn error::Error + 'static)> {
        match self {
            SwarmError::ConnectionLimit(err) => Some(err),
            SwarmError::NoAddresses(_) => None,
            SwarmError::NoConnection(_) => None,
            SwarmError::InvalidPeerId(_) => None,
            SwarmError::Transport(err) => Some(err),
            SwarmError::Internal => None,
            SwarmError::Closing(_) => None,
        }
    }
}

impl From<std::io::Error> for SwarmError {
    fn from(err: std::io::Error) -> Self {
        SwarmError::Transport(TransportError::IoError(err))
    }
}

impl From<TransportError> for SwarmError {
    fn from(err: TransportError) -> Self {
        SwarmError::Transport(err)
    }
}

impl From<mpsc::SendError> for SwarmError {
    // TODO: make a error catelog for SendError
    fn from(_: mpsc::SendError) -> Self {
        SwarmError::Internal
    }
}

impl From<oneshot::Canceled> for SwarmError {
    // TODO: make a error catelog for Canceled
    fn from(_: oneshot::Canceled) -> Self {
        SwarmError::Internal
    }
}

pub(crate) async fn open_stream<T>(
    cid: ConnectionId,
    mut stream_muxer: T,
    pids: Vec<ProtocolId>,
    mut tx: mpsc::UnboundedSender<SwarmEvent<T>>,
) -> Result<Substream<T::Substream>>
where
    T: StreamMuxer,
    T::Substream: Read2 + Write2 + Send + Unpin,
{
    let raw_stream = stream_muxer.open_stream().await?;

    // now it's time to do protocol multiplexing for sub stream
    let negotiator = Negotiator::new_with_protocols(pids);
    let result = negotiator.select_one(raw_stream).await;

    match result {
        Ok((proto, raw_stream)) => {
            log::info!("select_outbound {:?}", proto.protocol_name_str());

            let stream = Substream::new(raw_stream, Direction::Outbound, proto, cid);

            let sid = stream.id();
            let _ = tx
                .send(SwarmEvent::StreamOpened {
                    dir: Direction::Outbound,
                    cid,
                    sid,
                })
                .await;
            Ok(stream)
        }
        Err(err) => {
            let _ = tx
                .send(SwarmEvent::StreamError {
                    cid,
                    error: TransportError::Internal,
                })
                .await;
            Err(SwarmError::Transport(err.into()))
        }
    }
}

#[cfg(test)]
mod tests {}

//! High level manager of the network.
//!
//! A [`Swarm`] contains the state of the network as a whole. The entire
//! behaviour of a libp2p network can be controlled through the `Swarm`.
//! The `Swarm` struct contains all active and pending connections to
//! remotes and manages the state of all the substreams that have been
//! opened, and all the upgrades that were built upon these substreams.
//!
//! # Initializing a Swarm
//!
//! Creating a `Swarm` requires three things:
//!
//!  1. A network identity of the local node in form of a [`PeerId`].
//!  2. An implementation of the [`Transport`] trait. This is the type that
//!     will be used in order to reach nodes on the network based on their
//!     address. See the `transport` module for more information.
//!  3. An implementation of the [`NetworkBehaviour`] trait. This is a state
//!     machine that defines how the swarm should behave once it is connected
//!     to a node.
//!
//! # Network Behaviour
//!
//! The [`NetworkBehaviour`] trait is implemented on types that indicate to
//! the swarm how it should behave. This includes which protocols are supported
//! and which nodes to try to connect to. It is the `NetworkBehaviour` that
//! controls what happens on the network. Multiple types that implement
//! `NetworkBehaviour` can be composed into a single behaviour.
//!
//! # Protocols Handler
//!
//! The [`ProtocolsHandler`] trait defines how each active connection to a
//! remote should behave: how to handle incoming substreams, which protocols
//! are supported, when to open a new outbound substream, etc.
//!

//mod behaviour;
mod connection;
mod control;
mod network;
mod registry;

use crate::connection::{ConnectedPoint, Connection, ConnectionId, ConnectionLimit, Direction};
use crate::network::{NetworkInfo};

use crate::control::{Control, SwarmControlCmd};
use async_std::task;
use fnv::FnvHashMap;
use futures::channel::{mpsc, oneshot};
use futures::future::Either;
use futures::prelude::*;
use libp2p_core::peerstore::PeerStore;
use libp2p_core::secure_io::SecureInfo;
use libp2p_core::transport::TransportListener;
use libp2p_core::{muxing::StreamMuxer, transport::TransportError, Multiaddr, PeerId, Transport};
use registry::Addresses;
use smallvec::SmallVec;
use std::collections::HashSet;
use std::{error, fmt, hash::Hash};

type Result<T> = std::result::Result<T, SwarmError>;

/// The ID of a single listener.
///
/// It is part of most [`ListenersEvent`]s and can be used to remove
/// individual listeners from the [`ListenersStream`].
#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct ListenerId(u64);

/// A single active listener.
#[derive(Debug)]
struct Listener<TTrans>
where
    TTrans: Transport,
{
    /// The ID of this listener.
    id: ListenerId,
    /// The object that actually listens.
    listener: TTrans::Listener,
}

#[allow(dead_code)]
impl<TTrans> Listener<TTrans>
where
    TTrans: Transport,
{
    pub fn new(listener: TTrans::Listener, id: ListenerId) -> Self {
        Listener { id, listener }
    }
}

/// Event generated by the `Swarm`.
#[derive(Debug)]
pub enum SwarmEvent<TStreamMuxer, TSubstream> {
    /// A connection to the given peer has been opened.
    ConnectionEstablished {
        /// The connection, stream muxer
        stream_muxer: TStreamMuxer,
        /// Direction of the connection
        direction: Direction,
        /// The pending reply channel
        reply: Option<oneshot::Sender<Result<()>>>, /*
                                                            /// Number of established connections to this peer, including the one that has just been
                                                            /// opened.
                                                            num_established: NonZeroU32,
                                                    */
    },
    /// A connection with the given peer has been closed.
    ConnectionClosed {
        /// The connection, stream muxer
        stream_muxer: TStreamMuxer,
        conn_id: ConnectionId,
        /*
                num_established: u32,
                // /// Reason for the disconnection.
                // cause: ConnectionError<NodeHandlerWrapperError<THandleErr>>,
        */
    },
    /// A new substream arrived.
    StreamOpened {
        /// The substream
        stream: TSubstream,
    },
    /// A substream has been closed.
    StreamClosed {
        /// The substream
        stream: TSubstream,
    },
    /// An error happened on a connection during its initial handshake.
    ///
    /// This can include, for example, an error during the handshake of the encryption layer, or
    /// the connection unexpectedly closed.
    IncomingConnectionError {
        /// Local connection address.
        /// This address has been earlier reported with a [`NewListenAddr`](SwarmEvent::NewListenAddr)
        /// event.
        local_addr: Multiaddr,
        /// Address used to send back data to the remote.
        send_back_addr: Multiaddr,
        // The error that happened.
        error: TransportError,
    },
    OutgoingConnectionError {
        /// The remote Peer Id
        peer_id: PeerId,
        /// The remote multiaddr
        remote_addr: Multiaddr,
        /// The error that happened when dialing
        error: SwarmError,
        /// The pending reply channel
        reply: Option<oneshot::Sender<Result<()>>>,
    },
    /// We connected to a peer, but we immediately closed the connection because that peer is banned.
    BannedPeer {
        /// Identity of the banned peer.
        peer_id: PeerId,
        /// Endpoint of the connection that has been closed.
        endpoint: ConnectedPoint,
    },
    /// Tried to dial an address but it ended up being unreachaable.
    UnreachableAddr {
        /// `PeerId` that we were trying to reach.
        peer_id: PeerId,
        /// Address that we failed to reach.
        address: Multiaddr,
        // /// Error that has been encountered.
        // error: PendingConnectionError<io::Error>,
        /// Number of remaining connection attempts that are being tried for this peer.
        attempts_remaining: u32,
    },
    /// Tried to dial an address but it ended up being unreachaable.
    /// Contrary to `UnreachableAddr`, we don't know the identity of the peer that we were trying
    /// to reach.
    UnknownPeerUnreachableAddr {
        /// Address that we failed to reach.
        address: Multiaddr,
        // /// Error that has been encountered.
        // error: PendingConnectionError<io::Error>,
    },
    /// One of our listeners has reported a new local listening address.
    NewListenAddr(Multiaddr),
    /// One of our listeners has reported the expiration of a listening address.
    ExpiredListenAddr(Multiaddr),
    /// One of the listeners gracefully closed.
    ListenerClosed {
        /// The addresses that the listener was listening on. These addresses are now considered
        /// expired, similar to if a [`ExpiredListenAddr`](SwarmEvent::ExpiredListenAddr) event
        /// has been generated for each of them.
        addresses: Vec<Multiaddr>,
        /// Reason for the closure. Contains `Ok(())` if the stream produced `None`, or `Err`
        /// if the stream produced an error.
        reason: TransportError,
    },
    /// A new dialing attempt has been initiated.
    ///
    /// A [`ConnectionEstablished`](SwarmEvent::ConnectionEstablished)
    /// event is reported if the dialing attempt succeeds, otherwise a
    /// [`UnreachableAddr`](SwarmEvent::UnreachableAddr) event is reported
    /// with `attempts_remaining` equal to 0.
    Dialing(PeerId),
}

/// Contains the state of the network, plus the way it should behave.
pub struct Swarm<TTrans, THandler>
where
    TTrans: Transport + Clone,
    TTrans::Output: StreamMuxer,
    //    THandler: IntoProtocolsHandler,
    //    TConnInfo: ConnectionInfo<PeerId = PeerId>,
{
    pub peers: PeerStore,

    transport: TTrans,
    #[allow(dead_code)]
    handler: THandler,
    /// The local peer ID.
    local_peer_id: PeerId,

    /// The next connection ID to assign.
    next_connection_id: ConnectionId,

    /*    /// The next listener ID to assign.
        next_id: ListenerId,

    */    /*
            /// Handles which nodes to connect to and how to handle the events sent back by the protocol
            /// handlers.
            behaviour: TBehaviour,

        */
    /// List of protocols that the behaviour says it supports.
    #[allow(dead_code)]
    supported_protocols: SmallVec<[Vec<u8>; 16]>,

    /// List of multiaddresses we're listening on.
    listened_addrs: SmallVec<[Multiaddr; 8]>,

    /// List of multiaddresses we're listening on, after account for external IP addresses and
    /// similar mechanisms.
    external_addrs: Addresses,

    /// List of nodes for which we deny any incoming connection.
    banned_peers: HashSet<PeerId>,

    /// The established connections of each peer that are currently considered
    /// established
    established: FnvHashMap<PeerId, Vec<Connection<TTrans::Output>>>,

    /// The pending connections that are currently being negotiated.
    #[allow(dead_code)]
    pending: FnvHashMap<PeerId, Connection<TTrans::Output>>,
    //
    // /// Pending event to be delivered to connection handlers
    // /// (or dropped if the peer disconnected) before the `behaviour`
    // /// can be polled again.
    // pending_event: Option<(PeerId, PendingNotifyHandler, TInEvent)>
    /// Swarm will listen on this channel, waiting for events generated from underlying transport
    event_receiver:
        mpsc::Receiver<SwarmEvent<TTrans::Output, <TTrans::Output as StreamMuxer>::Substream>>,
    /// The Swarm event sender wil be cloned and then taken by underlying parts
    event_sender:
        mpsc::Sender<SwarmEvent<TTrans::Output, <TTrans::Output as StreamMuxer>::Substream>>,

    /// Swarm will listen on this channel, for external control commands
    ctrl_receiver: mpsc::Receiver<SwarmControlCmd<<TTrans::Output as StreamMuxer>::Substream>>,
    /// The Swarm event sender wil be cloned and then taken by others
    ctrl_sender: mpsc::Sender<SwarmControlCmd<<TTrans::Output as StreamMuxer>::Substream>>,
}

// impl<TBehaviour, TInEvent, TOutEvent, THandler, TConnInfo> Unpin for
//     Swarm<TBehaviour, TInEvent, TOutEvent, THandler, TConnInfo>
// where
//     THandler: IntoProtocolsHandler,
//     TConnInfo: ConnectionInfo<PeerId = PeerId>,
// {
// }
#[allow(dead_code)]
impl<TTrans, THandler> Swarm<TTrans, THandler>
where
    THandler: Send + 'static,
    TTrans: Transport + Clone + 'static,
    TTrans::Listener: 'static,
    TTrans::Output: StreamMuxer + SecureInfo,
    //TTrans::Listener::Output : StreamMuxer + SecureInfo,

    // TInEvent: Clone + Send + 'static,
    // TOutEvent: Send + 'static,
    // TConnInfo: ConnectionInfo<PeerId = PeerId> + fmt::Debug + Clone + Send + 'static,
    //THandler: IntoProtocolsHandler + Send + 'static,
    //THandler::Handler: ProtocolsHandler<InEvent = TInEvent, OutEvent = TOutEvent, Error = THandleErr>,
    //THandleErr: error::Error + Send + 'static,
{
    /// Builds a new `Swarm`.
    pub fn new(
        transport: TTrans,
        handler: THandler,
        local_peer_id: PeerId,
        //_config: NetworkConfig,
    ) -> Self
// where
    //     TMuxer: StreamMuxer + Send + Sync + 'static,
    //     TMuxer::OutboundSubstream: Send + 'static,
    //     <TMuxer as StreamMuxer>::OutboundSubstream: Send + 'static,
    //     <TMuxer as StreamMuxer>::Substream: Send + 'static,
    //     TTransport: Transport<Output = (TConnInfo, TMuxer)> + Clone + Send + Sync + 'static,
    //     TTransport::Error: Send + Sync + 'static,
    //     TTransport::Listener: Send + 'static,
    //     TTransport::ListenerUpgrade: Send + 'static,
    //     TTransport::Dial: Send + 'static,
    {
        let (event_tx, event_rx) = mpsc::channel(0);
        let (ctrl_tx, ctrl_rx) = mpsc::channel(0);
        Swarm {
            peers: PeerStore::default(),
            transport,
            local_peer_id,
            handler,
            // listeners: SmallVec::with_capacity(16),
            // next_id: ListenerId(1),
            supported_protocols: Default::default(),
            listened_addrs: Default::default(),
            external_addrs: Default::default(),
            banned_peers: Default::default(),
            established: Default::default(),
            pending: Default::default(),
            event_receiver: event_rx,
            event_sender: event_tx,
            ctrl_receiver: ctrl_rx,
            ctrl_sender: ctrl_tx,
            next_connection_id: 0,
        }
    }

    /// Get a controller for Swarm.
    pub fn control(&self) -> Control<<TTrans::Output as StreamMuxer>::Substream> {
        Control::new(self.ctrl_sender.clone())
    }

    /// Makes progress for Swarm
    /// in general, it should be spawned in a Task
    pub async fn next(&mut self) -> Result<()> {
        // TODO: check if terminated??

        // handle messages, which makes actual progress for Swarm
        self.handle_messages().await?;

        Ok(())
    }

    /// Handles events generated internally or externally
    ///
    /// invoked from `next_stream`
    async fn handle_messages(&mut self) -> Result<()> {
        loop {
            let either =
                future::select(self.event_receiver.next(), self.ctrl_receiver.next()).await;
            match either {
                Either::Left((evt, _)) => {
                    if let Some(evt) = evt {
                        self.on_event(evt).await?;
                    } else {
                        // we are closed anyway, break
                        log::debug!("Swarm event channel is closed, closing down...");
                        return Err(SwarmError::Closing(1));
                    }
                }
                Either::Right((cmd, _)) => {
                    if let Some(cmd) = cmd {
                        self.on_command(cmd).await?;
                    } else {
                        // we are closed anyway, break
                        log::debug!("Swarm control channel is closed, closing down...");
                        return Err(SwarmError::Closing(2));
                    }
                }
            }
        }
    }

    async fn on_event(
        &mut self,
        event: SwarmEvent<TTrans::Output, <TTrans::Output as StreamMuxer>::Substream>,
    ) -> Result<()> {
        log::trace!("got an Swarm event={:?}", event);

        match event {
            SwarmEvent::ListenerClosed { addresses:_, reason:_ } => {}
            SwarmEvent::ConnectionEstablished {
                stream_muxer,
                direction,
                reply,
            } => {
                let r = self.handle_new_connection(stream_muxer, direction).await;
                if let Some(reply) = reply {
                   let _= reply.send(r);
                }
            }
            SwarmEvent::ConnectionClosed {
                stream_muxer,
                conn_id,
            } => {
                let _= self.handle_close_connection(stream_muxer, conn_id).await;
            }
            SwarmEvent::OutgoingConnectionError {
                peer_id:_,
                remote_addr:_,
                error,
                reply,
            } => {
                if let Some(reply) = reply {
                    let _= reply.send(Err(error));
                }
                // handle the pending NewStream request
                // if let Some(id) = pending_request {
                //     log::trace!("pending NewStream request id={:?}", id);
                //     if let Some(reply) = self.pending_new_stream.remove(&id) {
                //         log::trace!("got pending request id={:?}, matched", id);
                //         log::trace!("sending error back the client e={:?}", error);
                //         reply.send(Err(SwarmError::from(error)));
                //     }
                // }
            }

            // TODO: handle other messages
            e => {
                log::warn!("TODO: unhandled swarm events {:?}", e);
            }
        }

        Ok(())
    }

    async fn on_command(
        &mut self,
        cmd: SwarmControlCmd<<TTrans::Output as StreamMuxer>::Substream>,
    ) -> Result<()> {
        log::trace!("got a Swarm control command={:?}", cmd);

        match cmd {
            SwarmControlCmd::NewConnection(peer_id, reply) => {
                // got the peer_id, start the dialer for it
                let _=  self.on_new_connection(peer_id, reply).await;
            }
            SwarmControlCmd::CloseConnection(peer_id, reply) => {
                // got the peer_id, close all connections to the peer
                let _=  self.on_close_connection(peer_id, reply).await;
            }
            SwarmControlCmd::NewStream(peer_id, reply) => {
                // got the peer_id, try opening a new sub stream
                let _= self.on_new_stream(peer_id, reply).await;
            }
            SwarmControlCmd::CloseSwarm => {
                log::info!("closing the swarm...");
                let _=  self.event_sender.close_channel();
            }

            // TODO:
            //_ => {}
        }

        Ok(())
    }

    async fn on_new_connection(
        &mut self,
        peer_id: PeerId,
        reply: oneshot::Sender<Result<()>>,
    ) -> Result<()> {
        // return if we already have the connection, otherwise, start dialing
        if let Some(_conn) = self.get_best_conn(&peer_id) {
            let _= reply.send(Ok(()));
        } else {
            // Note: reply moved
            let _= self.start_dialer(peer_id, Some(reply));
        }
        Ok(())
    }

    async fn on_close_connection(
        &mut self,
        peer_id: PeerId,
        reply: oneshot::Sender<Result<()>>,
    ) -> Result<()> {
        if let Some(conns) = self.established.get_mut(&peer_id) {
            // TODO: to check if this connection is being closed

            for conn in conns {
                let _= conn.muxer.close().await;
                // wait for accept-task and bg-task to exit
                conn.handle.as_mut().unwrap().await;
            }
        }

        let _=  reply.send(Ok(()));
        Ok(())
    }

    async fn on_new_stream(
        &mut self,
        peer_id: PeerId,
        reply: oneshot::Sender<Result<<TTrans::Output as StreamMuxer>::Substream>>,
    ) -> Result<()> {
        if let Some(conn) = self.get_best_conn(&peer_id) {
            // well, we have a connection, simply open a new stream
            let r = conn.muxer.open_stream().await.map_err(|e| e.into());
            let _= reply.send(r);
        } else {
            let _=  reply.send(Err(SwarmError::NoConnection(peer_id)));
        }
        Ok(())
    }

    /// Starts Swarm background task
    /// handling the internal events and external controls
    pub fn start(self) {
        // well, self 'move' explicitly,
        let mut swarm = self;

        task::spawn(async move { while let Ok(()) = swarm.next().await {} });
    }

    /// Returns the transport passed when building this object.
    pub fn transport(&self) -> &TTrans {
        &self.transport
    }

    /// Returns information about the [`Network`] underlying the `Swarm`.
    pub fn network_info(&self) -> NetworkInfo {
        // TODO: add stats later on
        let num_connections_established = 0; //self.pool.num_established();
        let num_connections_pending = 0; //self.pool.num_pending();
        let num_connections = num_connections_established + num_connections_pending;
        let num_peers = 0; //self.pool.num_connected();
        NetworkInfo {
            num_peers,
            num_connections,
            num_connections_established,
            num_connections_pending,
        }
    }

    /// Starts listening on the given address.
    ///
    /// Returns an error if the address is not supported.
    /// TODO: addr: Multiaddr might be a Vec<Multiaddr>
    pub fn listen_on(&mut self, addr: Multiaddr) -> Result<()> {
        let mut listener = self.transport.clone().listen_on(addr)?;

        self.listened_addrs.push(listener.multi_addr());

        // let id = self.next_id;
        // self.next_id = ListenerId(self.next_id.0 + 1);

        let mut tx = self.event_sender.clone();
        // start a task for this listener
        task::spawn(async move {
            loop {
                let r = listener.accept().await;
                match r {
                    Ok(muxer) => {
                        // dont have to verify if remote peer id matches its public key
                        // always accept any incoming connection

                        // send muxer back to Swarm main task
                        let _=  tx.send(SwarmEvent::ConnectionEstablished {
                            stream_muxer: muxer,
                            direction: Direction::Inbound,
                            reply: None,
                        })
                        .await;
                    }
                    Err(err) => {
                        let _=   tx.send(SwarmEvent::ListenerClosed {
                            addresses: vec![],
                            reason: err,
                        })
                        .await;
                    }
                }
            }
        });
        Ok(())
    }

    /*    /// Remove some listener.
        ///
        /// Returns `Ok(())` if there was a listener with this ID.
        pub fn remove_listener(&mut self, id: ListenerId) -> Result<()> {
            if let Some(i) = self.listeners.iter().position(|l| l.id == id) {
                self.listeners.remove(i);
                Ok(())
            } else {
                Err(SwarmError::Internal)
            }
        }
    */
    /// Tries to dial the given address.
    ///
    /// Returns an error if the address is not supported.
    fn dial_peer_with_addr(
        &mut self,
        peer_id: PeerId,
        addr: Multiaddr,
        reply: Option<oneshot::Sender<Result<()>>>,
    ) {
        // TODO: add dial limiter...

        log::trace!("dialing addr={:?}, expecting {:?}", addr, peer_id);

        let mut tx = self.event_sender.clone();
        let transport = self.transport().clone();
        task::spawn(async move {
            let r = transport.dial(addr.clone()).await;
            match r {
                Ok(mut stream_muxer) => {
                    // test if the PeerId matches expectation, otherwise,
                    // it is a bad outgoing connection
                    if peer_id == stream_muxer.remote_peer() {
                        let _=  tx.send(SwarmEvent::ConnectionEstablished {
                            stream_muxer,
                            direction: Direction::Outbound,
                            reply,
                        })
                        .await;
                    } else {
                        let wrong_id = stream_muxer.remote_peer();
                        log::info!(
                            "bad connection, peerid mismatch conn={:?} wanted={:?} got={:?}",
                            stream_muxer,
                            peer_id,
                            wrong_id
                        );
                        let _=  tx.send(SwarmEvent::OutgoingConnectionError {
                            peer_id,
                            remote_addr: addr,
                            error: SwarmError::InvalidPeerId(wrong_id),
                            reply,
                        })
                        .await;
                        // close this connection
                        let _= stream_muxer.close().await;
                    }
                }
                Err(err) => {
                    let _= tx.send(SwarmEvent::OutgoingConnectionError {
                        peer_id,
                        remote_addr: addr,
                        error: SwarmError::Transport(err),
                        reply,
                    })
                    .await;
                }
            }
        });
    }

    /// Starts a dialing task
    /// reply is optional, it might be 'None' when dialer is initiated internally
    pub fn start_dialer(
        &mut self,
        peer_id: PeerId,
        reply: Option<oneshot::Sender<Result<()>>>,
    ) -> Result<()> {
        log::trace!("dialer, looking for {:?}", peer_id);

        // TODO: find a better way to handle multiple addresses of PeerId
        if let Some(addrs) = self.peers.addrs.get_addr(&peer_id) {
            // TODO: handle multiple addresses

            // TODO: add dial limiter...

            let addr = addrs.first().expect("must have one").clone();
            self.dial_peer_with_addr(peer_id, addr, reply);

            Ok(())
        } else {
            Err(SwarmError::NoAddresses(peer_id))
        }
    }

    /// Tries to initiate a dialing attempt to the given peer.
    ///
    pub async fn dial_peer(&mut self, peer_id: PeerId) -> Result<()> {
        if let Some(_conn) = self.get_best_conn(&peer_id) {
            Ok(())
        } else {
            self.start_dialer(peer_id, None)
        }
    }

    fn get_best_conn(&mut self, peer_id: &PeerId) -> Option<&mut Connection<TTrans::Output>> {
        let mut best = None;
        // selects the best connection we have to the peer.
        // TODO: we might have multiple connections towards a PeerId

        log::trace!("trying to get the best connnection for {:?}", peer_id);

        self.established
            .iter()
            .for_each(|(k, v)| log::info!("{:?}={:?}", k, v));

        //let v = self.established.get_mut(peer_id).unwrap();

        if let Some(conns) = self.established.get_mut(peer_id) {
            // TODO: to check if this connection is being closed

            let mut len = 0;
            for conn in conns {
                if conn.substreams.len() >= len {
                    len = conn.substreams.len();
                    best = Some(conn);
                }
            }
        }
        best
    }

    fn is_connected(&self, peer_id: &PeerId) -> bool {
        // TODO: check if the connection is being closed??
        self.established.get(peer_id).map_or(0, |v| v.len()) > 0
    }

    /*
        /// Tries to initiate a dialing attempt to the given peer.
        ///
        /// If a new dialing attempt has been initiated, `Ok(true)` is returned.
        ///
        /// If no new dialing attempt has been initiated, meaning there is an ongoing
        /// dialing attempt or `addresses_of_peer` reports no addresses, `Ok(false)`
        /// is returned.
        pub fn dial(&mut self, peer_id: &PeerId) -> Result<(), SwarmError> {
            let self_listening = &self.listened_addrs;
            let mut addrs = self.behaviour.addresses_of_peer(peer_id)
                .into_iter()
                .filter(|a| !self_listening.contains(a));

            let result =
                if let Some(first) = addrs.next() {
                    let handler = self.behaviour.new_handler().into_node_handler_builder();
                    self.network.peer(peer_id.clone())
                        .dial(first, addrs, handler)
                        .map(|_| ())
                        .map_err(SwarmError::ConnectionLimit)
                } else {
                    Err(SwarmError::NoAddresses)
                };

            if let Err(error) = &result {
                log::debug!(
                    "New dialing attempt to peer {:?} failed: {:?}.",
                    peer_id, error);
                self.behaviour.inject_dial_failure(&peer_id);
            }

            result
        }
        /// Returns an iterator that produces the list of addresses we're listening on.
        pub fn listeners(&self) -> impl Iterator<Item = &Multiaddr> {
            self.listeners.iter().flat_map(|l| l.addresses.iter())
        }
    */

    /// Returns an iterator that produces the list of addresses that other nodes can use to reach
    /// us.
    pub fn external_addresses(&self) -> impl Iterator<Item = &Multiaddr> {
        self.external_addrs.iter()
    }

    /// Returns the peer ID of the swarm passed as parameter.
    pub fn local_peer_id(&self) -> &PeerId {
        &self.local_peer_id
    }

    /// Adds an external address.
    ///
    /// An external address is an address we are listening on but that accounts for things such as
    /// NAT traversal.
    pub fn add_external_address(&mut self, addr: Multiaddr) {
        self.external_addrs.add(addr)
    }
    /*
        /// Obtains a view of a [`Peer`] with the given ID in the network.
        pub fn peer(&mut self, peer_id: TPeerId)
                    -> Peer<'_, TTrans, TInEvent, TOutEvent, THandler, TConnInfo, TPeerId>
        {
            Peer::new(self, peer_id)
        }

        /// Returns the connection info for an arbitrary connection with the peer, or `None`
        /// if there is no connection to that peer.
        // TODO: should take &self instead of &mut self, but the API in network requires &mut
        pub fn connection_info(&mut self, peer_id: &PeerId) -> Option<TConnInfo> {
            if let Some(mut n) = self.network.peer(peer_id.clone()).into_connected() {
                Some(n.some_connection().info().clone())
            } else {
                None
            }
        }
    */
    /// Bans a peer by its peer ID.
    ///
    /// Any incoming connection and any dialing attempt will immediately be rejected.
    /// This function has no effect is the peer is already banned.
    pub fn ban_peer_id(&mut self, peer_id: PeerId) {
        self.banned_peers.insert(peer_id);

        // TODO: to disconnect
        // if let Some(c) = self.network.peer(peer_id).into_connected() {
        //     c.disconnect();
        // }
    }

    /// Unbans a peer.
    pub fn unban_peer_id(&mut self, peer_id: PeerId) {
        self.banned_peers.remove(peer_id.as_ref());
    }

    fn add_connection(&mut self, conn: Connection<TTrans::Output>) {
        let remote_peer_id = conn.remote_peer();

        // append to the hashmap
        let conns = self.established.entry(remote_peer_id).or_default();
        conns.push(conn);

        log::trace!(
            "connection added to hashmap, total={}",
            self.established.len()
        );

        // TODO: we have a connection to the specified peer_id, now cancel all pending attempts

        // TODO: generate a connected event

        // TODO: start the connection in a background task

        // TODO: return the connection
    }

    // Assign a unique connection Id
    fn assign_conn_id(&mut self) -> ConnectionId {
        self.next_connection_id += 1;
        self.next_connection_id
    }

    /// Handles a new connection
    ///
    /// start a Task for accepting new sub-stream from the connection
    pub async fn handle_new_connection(
        &mut self,
        stream_muxer: TTrans::Output,
        dir: Direction,
    ) -> Result<()> {
        log::trace!("handle_new_connection: {:?} Dir={:?}", stream_muxer, dir);

        // clone the stream_muxer, and then wrap into Connection, task_handle will be assigned later
        let mut conn = Connection::new(self.assign_conn_id(), stream_muxer.clone(), dir);

        // TODO: filtering the multiaddr, Err = AddrFiltered(addr)

        /*        raddr := tc.RemoteMultiaddr()
                if s.Filters.AddrBlocked(raddr) {
                    tc.Close()
                    return nil, ErrAddrFiltered
                }

                p := tc.RemotePeer()

                // Add the public key.
                if pk := tc.RemotePublicKey(); pk != nil {
                    s.peers.AddPubKey(p, pk)
                }
        */
        // TODO: add remote pubkey to keystore

        let mut tx = self.event_sender.clone();
        let conn_id = conn.id();
        let handle = task::spawn(async move {
            let mut stream_muxer = stream_muxer;

            // start the background task of the stream_muxer, the handle can be await'ed by us
            let task_handle = stream_muxer.task().map(task::spawn);
            loop {
                let r = stream_muxer.accept_stream().await;
                match r {
                    Ok(stream) => {
                        let _=  tx.send(SwarmEvent::StreamOpened { stream }).await;
                    }
                    Err(_err) => {
                        let _=  tx.send(SwarmEvent::ConnectionClosed {
                            stream_muxer,
                            conn_id,
                        })
                        .await;

                        // something happened, break the loop then exit the Task
                        break;
                    }
                }
            }

            // As stream_muxer is closed, we wait for its task_handle
            if let Some(handle) = task_handle {
                handle.await;
            }
        });

        // now we have the handle, move it into Connection
        conn.handle = Some(handle);

        // insert to the hashmap of connections
        self.add_connection(conn);

        Ok(())
    }

    /// Handles closing a connection
    ///
    /// start a Task for accepting new sub-stream from the connection
    pub async fn handle_close_connection(
        &mut self,
        stream_muxer: TTrans::Output,
        conn_id: ConnectionId,
    ) -> Result<()> {
        log::info!("before close {:?}", self.established);

        log::trace!(
            "handle_close_connection: {:?} ConnectionId={:?}",
            stream_muxer,
            conn_id
        );

        let remote_peer_id = stream_muxer.remote_peer();

        if let Some(conns) = self.established.get_mut(&remote_peer_id) {
            // let x = conns.iter_mut().find(|c| c.id == conn_id);
            // if let Some(c) = x {
            //     c.handle.as_mut().unwrap().await;
            // }

            let mut index: usize = 0;
            for conn in conns.iter_mut() {
                if conn.id == conn_id {
                    // wait for the Task
                    log::trace!("about to remove connection {:?} at index={}", conn, index);
                    break;
                }
                index += 1;
            }

            conns.remove(index);
        } else {
            log::warn!("shouldn't happen");
        }

        log::info!("after close {:?}", self.established);

        Ok(())
    }
}

/// Connections to notify of a pending event.
///
/// The connection IDs to notify of an event are captured at the time
/// the behaviour emits the event, in order not to forward the event
/// to new connections which the behaviour may not have been aware of
/// at the time it issued the request for sending it.
#[allow(dead_code)]
enum PendingNotifyHandler {
    One(ConnectionId),
    Any(SmallVec<[ConnectionId; 10]>),
    All(SmallVec<[ConnectionId; 10]>),
}

/// The possible failures of [`Swarm`].
#[derive(Debug)]
pub enum SwarmError {
    /// The configured limit for simultaneous outgoing connections
    /// has been reached.
    ConnectionLimit(ConnectionLimit),
    /// Returned no addresses for the peer to dial.
    NoAddresses(PeerId),
    /// No connection yet, unable to open a sub stream.
    NoConnection(PeerId),
    /// The peer identity obtained on the connection did not
    /// match the one that was expected.
    InvalidPeerId(PeerId),

    /// Closing down. Swarm is being closed at this moment
    /// 1: event channel, 2: ctrl channel
    Closing(u32),

    /// Transport Error
    ///
    /// Contains a TransportError.
    Transport(TransportError),

    /// Internal, tentatively for convenience
    Internal,
}

impl fmt::Display for SwarmError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            SwarmError::ConnectionLimit(err) => write!(f, "Swarm Dial error: {}", err),
            SwarmError::NoAddresses(peer_id) => {
                write!(f, "Swarm Dial error: no addresses for peer{:?}.", peer_id)
            }
            SwarmError::NoConnection(peer_id) => write!(
                f,
                "Swarm Stream error: no connections for peer{:?}.",
                peer_id
            ),
            SwarmError::InvalidPeerId(peer_id) => {
                write!(f, "Swarm Dial error: invalid peer id{:?}.", peer_id)
            }
            SwarmError::Transport(err) => write!(f, "Swarm Transport error: {}.", err),
            SwarmError::Internal => write!(f, "Swarm internal error."),
            SwarmError::Closing(s) => write!(f, "Swarm channel closed source={}.", s),
        }
    }
}

impl error::Error for SwarmError {
    fn source(&self) -> Option<&(dyn error::Error + 'static)> {
        match self {
            SwarmError::ConnectionLimit(err) => Some(err),
            SwarmError::NoAddresses(_) => None,
            SwarmError::NoConnection(_) => None,
            SwarmError::InvalidPeerId(_) => None,
            SwarmError::Transport(err) => Some(err),
            SwarmError::Internal => None,
            SwarmError::Closing(_) => None,
        }
    }
}

impl From<TransportError> for SwarmError {
    fn from(err: TransportError) -> Self {
        SwarmError::Transport(err)
    }
}

impl From<mpsc::SendError> for SwarmError {
    // TODO: make a error catelog for SendError
    fn from(_: mpsc::SendError) -> Self {
        SwarmError::Internal
    }
}

impl From<oneshot::Canceled> for SwarmError {
    // TODO: make a error catelog for Canceled
    fn from(_: oneshot::Canceled) -> Self {
        SwarmError::Internal
    }
}

#[cfg(test)]
mod tests {}
